{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ff9b39-2c2a-4be3-8f7f-c6975653c47a",
   "metadata": {},
   "source": [
    "# 機械学習スクラッチ入門\n",
    "\n",
    "\n",
    "NumPy などに備わっている基本的なライブラリを組み合わせることで、\n",
    "\n",
    "scikit-learn などの応用的なライブラリに実装されている機能と等価なクラス・関数を自作することができます。\n",
    "\n",
    "**これをスクラッチと呼びます。**\n",
    "\n",
    "\n",
    "スクラッチを通して、scikit-learnなどのライブラリを動かすだけでは掴みづらい、アルゴリズムの深い理解を目指します。\n",
    "\n",
    "コーディングのスキル向上も兼ねていますが、それは主な目的ではありません。\n",
    "\n",
    "\n",
    "以下のような効果を狙っています。\n",
    "\n",
    "\n",
    "**1. 新たな手法に出会った時に理論・数式を理解しやすくする**\n",
    "\n",
    "\n",
    "**2. ライブラリを使う上での曖昧さを減らす**\n",
    "\n",
    "\n",
    "**3. 既存の実装を読みやすくする**\n",
    "\n",
    "\n",
    "今回はまず、機械学習のプログラムを完全にはスクラッチせず、scikit-learn を用いて実装します。\n",
    "\n",
    "そして、次回から段階的に scikit-learn を用いた実装をスクラッチに移行していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9dd04d83-92a7-4aa7-ba1a-0fb65539c153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fd2cba-5f91-438d-8e60-42b33476e220",
   "metadata": {},
   "source": [
    "## 【問題1】train_test_split のスクラッチ\n",
    "\n",
    "まずは、scikit-learnの train_test_split をスクラッチしてみます。\n",
    "\n",
    "以下の雛形をベースに関数を実装してください。\n",
    "\n",
    "\n",
    "sklearn.model_selection.train_test_split - scikit-learn stable version documentation\n",
    "\n",
    "\n",
    "なお、作成した関数がscikit-learnの train_test_split と同じ動作をするか必ず確認をしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8b1d4d0-de6e-4eac-a68d-7a08ae5573d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分割結果 配列 \n",
      "x_train :[[245 246 247 248 249]\n",
      " [ 80  81  82  83  84]\n",
      " [205 206 207 208 209]\n",
      " [175 176 177 178 179]\n",
      " [220 221 222 223 224]]\n",
      "x_test  :[[ 45  46  47  48  49]\n",
      " [185 186 187 188 189]\n",
      " [ 15  16  17  18  19]\n",
      " [125 126 127 128 129]\n",
      " [ 35  36  37  38  39]]\n",
      "y_train :[46  5  3 10 33]\n",
      "y_test  :[20 28  4 41 34]\n",
      "分割結果 length \n",
      "x_train :40\n",
      "x_test  :10\n",
      "y_train :40\n",
      "y_test  :10\n",
      "分割結果 type \n",
      "x_train :<class 'numpy.ndarray'>\n",
      "x_test  :<class 'numpy.ndarray'>\n",
      "y_train :<class 'numpy.ndarray'>\n",
      "y_test  :<class 'numpy.ndarray'>\n",
      "分割結果 shape \n",
      "x_train :(40, 5)\n",
      "x_test  :(10, 5)\n",
      "y_train :(40,)\n",
      "y_test  :(10,)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def scratch_train_test_split(x, y, train_size=0.8, seed=32):\n",
    "    \"\"\"検証データを分割する。\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray\n",
    "      訓練データ (n_samples, n_features)\n",
    "    y : ndarray\n",
    "      正解値 (n_samples,)\n",
    "    train_size : float\n",
    "      何割をtrainとするか指定 (0 < train_size < 1)\n",
    "    Returns\n",
    "    -------\n",
    "    x_train : ndarray\n",
    "      訓練データ (n_samples, n_features)\n",
    "    x_test : ndarray\n",
    "      検証データ (n_samples, n_features)\n",
    "    y_train : ndarray\n",
    "      訓練データの正解値 (n_samples,)\n",
    "    y_test : ndarray\n",
    "      検証データの正解値 (n_samples,)\n",
    "    \"\"\"\n",
    "# １ndarrayを中身ランダムに分割\n",
    "# ２分割の割合は任意の数字を指定できるようにする\n",
    "    random.seed(0)\n",
    "    np.random.seed(seed=32)\n",
    "    np.random.shuffle(x) #ランダム\n",
    "    np.random.shuffle(y)\n",
    "\n",
    "    x_train, x_test = np.split(x, [int(len(x) * train_size)])\n",
    "    y_train, y_test = np.split(y, [int(len(y) * train_size)])\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "# 適当な配列を用意\n",
    "\n",
    "x = np.arange(250).reshape(50, 5)#説明変数は複数列\n",
    "y = np.arange(50)#目的変数は１列\n",
    "\n",
    "x_train, x_test, y_train, y_test = scratch_train_test_split(x, y, train_size=0.8,seed=32)\n",
    "\n",
    "# 分割の実行結果\n",
    "print(f'分割結果 配列 \\nx_train :{x_train[0:5]}')\n",
    "print(f'x_test  :{x_test[0:5]}')\n",
    "print(f'y_train :{y_train[0:5]}')\n",
    "print(f'y_test  :{y_test[0:5]}')\n",
    "\n",
    "print(f'分割結果 length \\nx_train :{len(x_train)}')\n",
    "print(f'x_test  :{len(x_test)}')\n",
    "print(f'y_train :{len(y_train)}')\n",
    "print(f'y_test  :{len(y_test)}')\n",
    "\n",
    "print(f'分割結果 type \\nx_train :{type(x_train)}')\n",
    "print(f'x_test  :{type(x_test)}')\n",
    "print(f'y_train :{type(y_train)}')\n",
    "print(f'y_test  :{type(y_test)}')\n",
    "\n",
    "print(f'分割結果 shape \\nx_train :{x_train.shape}')\n",
    "print(f'x_test  :{x_test.shape}')\n",
    "print(f'y_train :{y_train.shape}')\n",
    "print(f'y_test  :{y_test.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "20f6d7e9-efe4-4393-80c4-7ee9171cf7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# # 本物\n",
    "# a_train, a_test, b_train, b_test = train_test_split(x, y, train_size=0.8)\n",
    "    \n",
    "# print(len(a_train))\n",
    "# print(len(a_test))\n",
    "# print(len(b_train))\n",
    "# print(len(b_test))\n",
    "\n",
    "# print('-------------')\n",
    "# print(a_train.shape)\n",
    "# print(a_test.shape)\n",
    "# print(b_train.shape)\n",
    "# print(b_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ad51d5-0799-4672-b699-92673869489f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分割結果 配列 \n",
      "x_train :[[245 246 247 248 249]\n",
      " [ 80  81  82  83  84]\n",
      " [205 206 207 208 209]]\n",
      "x_test  :[[ 45  46  47  48  49]\n",
      " [185 186 187 188 189]\n",
      " [ 15  16  17  18  19]\n",
      " [125 126 127 128 129]\n",
      " [ 35  36  37  38  39]\n",
      " [ 95  96  97  98  99]\n",
      " [120 121 122 123 124]\n",
      " [ 25  26  27  28  29]\n",
      " [215 216 217 218 219]\n",
      " [115 116 117 118 119]]\n",
      "y_train :[46  5  3]\n",
      "y_test  :[20 28  4]\n"
     ]
    }
   ],
   "source": [
    "print(f'分割結果 配列 \\nx_train :{x_train[:3]}')\n",
    "print(f'x_test  :{x_test}')\n",
    "print(f'y_train :{y_train[:3]}')\n",
    "print(f'y_test  :{y_test[:3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61370a-97ef-493a-8715-f37355699e12",
   "metadata": {},
   "source": [
    "### scikit-learnを用いて機械学習を行うコードの実装\n",
    "\n",
    "\n",
    "scikit-learnを使ったコードを実装しベースラインモデルを作成していきます。\n",
    "\n",
    "\n",
    "\n",
    "検証データの分割には問題1で作成した自作の関数を用いてください。クロスバリデーションではなくホールドアウト法で構いません。\n",
    "\n",
    "\n",
    "分類問題\n",
    "\n",
    "分類は3種類の手法をscikit-learnを使って実装します。\n",
    "\n",
    "\n",
    "**1. ロジスティック回帰**\n",
    "\n",
    "**2. SVM**\n",
    "\n",
    "**3. 決定木**\n",
    "\n",
    "scikit-learnにおいてLogisticRegressionクラスとSGDClassifierクラスの2種類から使用できます。\n",
    "\n",
    "ここでは勾配降下法を用いて計算するSGDClassifierクラスを利用してください。\n",
    "\n",
    "**引数でloss=”log”とすることでロジスティック回帰の計算になります。**\n",
    "\n",
    "\n",
    "scikit-learn にはロジスティック回帰に使える分類器として LogisticRegression クラスと SGDClassifier クラスが用意されています。\n",
    "\n",
    "ここでは勾配降下法を用いて計算する SGDClassifier クラスを用います。\n",
    "\n",
    "引数で loss=\"log\" を指定することでロジスティック回帰の計算ができます。\n",
    "\n",
    "\n",
    "3種類のデータセットを用いて動作を確認します。\n",
    "\n",
    "\n",
    "\n",
    "**1つ目は事前学習期間同様のirisデータセットです。**\n",
    "\n",
    "\n",
    "sklearn.datasets.load_iris - scikit-learn stable version documentation\n",
    "\n",
    "\n",
    "**2値分類としたいため、以下の2つの目的変数のみ利用します。特徴量は4種類すべて使います。**\n",
    "\n",
    "\n",
    "#### virgicolorとvirginica\n",
    "\n",
    "**残り2つは特徴量が2つのデータセットを人工的に用意します。**\n",
    "\n",
    "以下のコードで説明変数X,目的変数yが作成可能です。\n",
    "\n",
    "**「シンプルデータセット1」「シンプルデータセット2」とします。特徴量が2つであるため可視化が容易です。**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01b27eb7-b825-4433-bb3b-3590e8f6b785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "(100, 4)\n",
      "(80, 4)\n",
      "(20, 4)\n",
      "(80,)\n",
      "(20,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 1.アイリスデータセット準備\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "x_iris_df = pd.DataFrame(iris.data, columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])\n",
    "t_iris_df = pd.DataFrame(iris.target, columns=[\"TARGET\"])\n",
    "iris_df = pd.concat([x_iris_df,t_iris_df],axis=1)\n",
    "iris_df = iris_df.loc[(iris_df[\"TARGET\"] == 1 )|(iris_df[\"TARGET\"] == 2)].reset_index(drop=True) \n",
    "\n",
    "# 完成 ndarray（ターゲットを１と２のみ 100 rows × 5 columns）\n",
    "iris_x = iris_df[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]].values\n",
    "iris_y = iris_df[\"TARGET\"].values\n",
    "\n",
    "print(iris_x.shape)\n",
    "print(iris_x.shape)\n",
    "\n",
    "# 利用データ\n",
    "xi_train, xi_test, yi_train, yi_test = scratch_train_test_split(iris_x, iris_y, train_size=0.8)\n",
    "# xi_train, xi_test, yi_train, yi_test = train_test_split(iris_x, iris_y, train_size=0.8) #本物\n",
    "print(xi_train.shape)\n",
    "print(xi_test.shape)\n",
    "print(yi_train.shape)\n",
    "print(yi_test.shape)\n",
    "\n",
    "print(type(xi_train))\n",
    "print(type(xi_test))\n",
    "print(type(yi_train))\n",
    "print(type(yi_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fde40c3-fe3f-4adf-84c8-1f9000900538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2)\n",
      "(100, 2)\n",
      "(400,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "# 2.シンプルデータセット1作成コード\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, n_samples // 2)\n",
    "f1 = np.random.multivariate_normal(f1, cov, n_samples // 2)\n",
    "# 完成\n",
    "X = np.concatenate([f0, f1])\n",
    "Y = np.concatenate([\n",
    "    np.full(n_samples // 2, 1),\n",
    "    np.full(n_samples // 2, -1)\n",
    "])\n",
    "# targetは１か−１\n",
    "X_train, X_test, Y_train, Y_test = scratch_train_test_split(X, Y, train_size=0.8)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d007f96-861c-4430-a72f-eefc14dba53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.シンプルデータセット2作成コード\n",
    "XX = np.array([\n",
    "    [-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "    [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "    [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "    [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "    [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "    [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "    [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "    [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "    [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "    [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "    [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "    [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "    [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "    [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "    [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "    [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "    [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "    [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "    [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "    [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ],\n",
    "])\n",
    "YY = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "# 利用データ\n",
    "XX_train, XX_test, YY_train, YY_test = scratch_train_test_split(XX, YY, train_size=0.8)\n",
    "# print(XX_train, XX_test, YY_train, YY_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b8d28-f46e-46c4-a932-7bfdb97ca88b",
   "metadata": {},
   "source": [
    "## 【問題2】 分類問題を解くコードの作成\n",
    "\n",
    "\n",
    "**上記3種類の手法で3種類のデータセットを学習・推定するコードを作成してください。**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "317e96a4-f0bb-48d8-85a6-dfb378acd9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ロジスティック回帰\n",
      "fitのデータ: \n",
      "['アヤメ', SGDClassifier(loss='log', random_state=42), 'シンンプルデータ1', SGDClassifier(loss='log', random_state=42), 'シンンプルデータ2', SGDClassifier(loss='log', random_state=42)]\n",
      "predict : \n",
      "['アヤメ', array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'シンンプルデータ1', array([-1, -1, -1,  1,  1, -1,  1,  1,  1, -1, -1, -1,  1,  1, -1,  1, -1,\n",
      "       -1, -1, -1,  1,  1, -1,  1, -1, -1, -1,  1,  1, -1,  1, -1, -1,  1,\n",
      "       -1,  1,  1,  1, -1, -1,  1, -1, -1, -1,  1, -1, -1,  1, -1, -1,  1,\n",
      "        1,  1, -1,  1, -1, -1,  1, -1,  1,  1,  1,  1,  1,  1, -1, -1,  1,\n",
      "        1, -1, -1,  1,  1,  1, -1,  1, -1, -1, -1,  1,  1,  1, -1,  1, -1,\n",
      "       -1,  1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1]), 'シンンプルデータ2', array([0, 0, 1, 1, 0, 1, 0, 1])]\n",
      "score   : \n",
      "['アヤメ', 0.75, 'シンンプルデータ1', 0.41, 'シンンプルデータ2', 0.625]\n",
      "train-score : \n",
      "['アヤメ', 0.4375, 'シンンプルデータ1', 0.5375, 'シンンプルデータ2', 0.5]\n",
      "結果: アヤメは学習用よりテスト用の方が判定結果が良い。\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# 1. ロジスティック回帰\n",
    "# \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3 ,loss=\"log\", random_state=42)\n",
    "\n",
    "# for文で３つの学習を繰り返す\n",
    "# 繰り返し処理→①②.fitの中身を訓練データで入れ替える\n",
    "# 各データをリストに格納、for文で結果、学習結果をリストに格納\n",
    "\n",
    "# このデータを３回分の分類器で回す\n",
    "base_data = []\n",
    "base_data.append((xi_train, xi_test, yi_train, yi_test,\"アヤメ\"))\n",
    "base_data.append((X_train, X_test, Y_train, Y_test,\"シンンプルデータ1\"))\n",
    "base_data.append((XX_train, XX_test, YY_train, YY_test,\"シンンプルデータ2\"))\n",
    "\n",
    "fit_data = []\n",
    "sgd_predict = []\n",
    "sgd_score = []\n",
    "sgd_train_score_0 = []\n",
    "\n",
    "for model_train, model_test, t_train, t_test, name in base_data:\n",
    "    # 学習 fit\n",
    "    fit_answer = sgd_clf.fit(model_train, t_train)\n",
    "    fit_data.append(name)\n",
    "    fit_data.append(fit_answer)\n",
    "    # 推定 predict\n",
    "    predict = sgd_clf.predict(model_test)\n",
    "    sgd_predict.append(name)\n",
    "    sgd_predict.append(predict)\n",
    "    # 結果 score\n",
    "    score = sgd_clf.score(model_test, t_test)\n",
    "    sgd_score.append(name)\n",
    "    sgd_score.append(score)\n",
    "    # 学習用結果\n",
    "    sgd_train_score01 = sgd_clf.score(model_train, t_train)\n",
    "    sgd_train_score_0.append(name)\n",
    "    sgd_train_score_0.append(sgd_train_score01)\n",
    "\n",
    "print('1. ロジスティック回帰')\n",
    "print(f'fitのデータ: \\n{fit_data}')\n",
    "print(f'predict : \\n{sgd_predict}')   \n",
    "print(f'score   : \\n{sgd_score}')   \n",
    "print(f'train-score : \\n{sgd_train_score_0}')\n",
    "print('結果: アヤメは学習用よりテスト用の方が判定結果が良い。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1698904c-9ded-4c0e-80bb-49ec433d998b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. SVM\n",
      "fitのデータ: \n",
      "['アヤメ', Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(gamma='auto'))]), 'シンンプルデータ1', Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(gamma='auto'))]), 'シンンプルデータ2', Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(gamma='auto'))])]\n",
      "predict : \n",
      "['アヤメ', array([2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1]), 'シンンプルデータ1', array([-1, -1, -1,  1,  1,  1, -1,  1, -1, -1, -1,  1,  1,  1,  1,  1,  1,\n",
      "       -1, -1, -1, -1,  1, -1,  1, -1, -1, -1, -1,  1, -1,  1, -1, -1,  1,\n",
      "       -1,  1,  1,  1, -1, -1,  1, -1, -1, -1,  1, -1, -1,  1, -1, -1,  1,\n",
      "        1,  1, -1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,\n",
      "        1,  1,  1,  1,  1,  1, -1,  1, -1, -1, -1,  1,  1,  1, -1,  1,  1,\n",
      "        1,  1,  1,  1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1]), 'シンンプルデータ2', array([0, 0, 0, 0, 0, 0, 0, 1])]\n",
      "score   : \n",
      "['アヤメ', 0.5, 'シンンプルデータ1', 0.46, 'シンンプルデータ2', 0.5]\n",
      "train-score : \n",
      "['アヤメ', 0.7125, 'シンンプルデータ1', 0.55, 'シンンプルデータ2', 0.625]\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# 2. SVM\n",
    "# \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "svm_clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "fit_data_1 = []\n",
    "sgd_predict_1 = []\n",
    "sgd_score_1 = []\n",
    "sgd_train_score = []\n",
    "for model_train, model_test, t_train, t_test, name in base_data:\n",
    "    # 学習 fit\n",
    "    fit_answer = svm_clf.fit(model_train, t_train)\n",
    "    fit_data_1.append(name)\n",
    "    fit_data_1.append(fit_answer)\n",
    "    # 推定 predict\n",
    "    predict = svm_clf.predict(model_test)\n",
    "    sgd_predict_1.append(name)\n",
    "    sgd_predict_1.append(predict)\n",
    "    # 結果 score\n",
    "    score = svm_clf.score(model_test, t_test)\n",
    "    sgd_score_1.append(name)\n",
    "    sgd_score_1.append(score)\n",
    "    \n",
    "    svm_train_score = svm_clf.score(model_train, t_train)\n",
    "    sgd_train_score.append(name)\n",
    "    sgd_train_score.append(svm_train_score)\n",
    "\n",
    "print('2. SVM')\n",
    "print(f'fitのデータ: \\n{fit_data_1}')\n",
    "print(f'predict : \\n{sgd_predict_1}')   \n",
    "print(f'score   : \\n{sgd_score_1}')   \n",
    "print(f'train-score : \\n{sgd_train_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "03f40803-4064-4c45-a170-021d4cf71863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. 決定木\n",
      "fitのデータ: \n",
      "['アヤメ', Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('decisiontreeclassifier',\n",
      "                 DecisionTreeClassifier(random_state=0))]), 'シンンプルデータ1', Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('decisiontreeclassifier',\n",
      "                 DecisionTreeClassifier(random_state=0))]), 'シンンプルデータ2', Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('decisiontreeclassifier',\n",
      "                 DecisionTreeClassifier(random_state=0))])]\n",
      "predict : \n",
      "['アヤメ', array([2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1]), 'シンンプルデータ1', array([ 1,  1, -1,  1, -1, -1, -1,  1, -1, -1,  1, -1,  1,  1, -1, -1, -1,\n",
      "       -1,  1, -1, -1,  1, -1,  1,  1,  1, -1,  1, -1,  1, -1, -1,  1,  1,\n",
      "       -1,  1,  1,  1, -1,  1, -1, -1, -1, -1,  1,  1, -1, -1,  1,  1,  1,\n",
      "        1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1, -1, -1,\n",
      "        1, -1, -1, -1,  1,  1, -1, -1, -1,  1,  1,  1, -1,  1,  1, -1,  1,\n",
      "       -1, -1,  1,  1, -1,  1,  1, -1,  1, -1,  1,  1,  1, -1,  1]), 'シンンプルデータ2', array([1, 0, 1, 0, 0, 1, 0, 1])]\n",
      "score   : \n",
      "['アヤメ', 0.45, 'シンンプルデータ1', 0.51, 'シンンプルデータ2', 0.625]\n",
      "train-score : \n",
      "['アヤメ', 0.9875, 'シンンプルデータ1', 1.0, 'シンンプルデータ2', 1.0]\n",
      "結果:過学習が起きている。traindataのみ適合している\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# 3. 決定木\n",
    "# \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = make_pipeline(StandardScaler(), DecisionTreeClassifier(random_state=0))\n",
    "fit_data_2 = []\n",
    "sgd_predict_2 = []\n",
    "sgd_score_2 = []\n",
    "sgd_train = []\n",
    "for model_train, model_test, t_train, t_test, name in base_data:\n",
    "    # 学習 fit\n",
    "    fit_answer = tree_clf.fit(model_train, t_train)\n",
    "    fit_data_2.append(name)\n",
    "    fit_data_2.append(fit_answer)\n",
    "    # 推定 predict\n",
    "    predict = tree_clf.predict(model_test)\n",
    "    sgd_predict_2.append(name)\n",
    "    sgd_predict_2.append(predict)\n",
    "    # 結果 score\n",
    "    score = tree_clf.score(model_test, t_test)\n",
    "    sgd_score_2.append(name)\n",
    "    sgd_score_2.append(score)\n",
    "    # 学習用の結果\n",
    "    train_score = tree_clf.score(model_train, t_train)\n",
    "    sgd_train.append(name)\n",
    "    sgd_train.append(train_score)\n",
    "\n",
    "print('3. 決定木')\n",
    "print(f'fitのデータ: \\n{fit_data_2}')\n",
    "print(f'predict : \\n{sgd_predict_2}')   \n",
    "print(f'score   : \\n{sgd_score_2}')   \n",
    "print(f'train-score : \\n{sgd_train}')   \n",
    "print('結果:過学習が起きている。traindataのみ適合している')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7ece14-c134-47fc-bf0d-69eb2688a103",
   "metadata": {},
   "source": [
    "#### 回帰問題\n",
    "\n",
    "次に回帰は1種類をscikit-learnを使って実装します。\n",
    "\n",
    "\n",
    "**線形回帰**\n",
    "\n",
    "線形回帰は勾配降下法を用いて計算する SGDRegressor クラスを利用してください。\n",
    "\n",
    "\n",
    "sklearn.linear_model.SGDRegressor - scikit-lear stable version documentation\n",
    "\n",
    "\n",
    "データセットは事前学習期間同様にHouse Pricesコンペティションのものを使います。\n",
    "\n",
    "\n",
    "House Prices: Advanced Regression Techniques\n",
    "\n",
    "\n",
    "**train.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。**\n",
    "\n",
    "## 【問題3】 回帰問題を解くコードの作成\n",
    "\n",
    "線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "95b8c22b-c021-4cbe-9a10-00753c95e899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 線形回帰\n",
      "fitのデータ: \n",
      "SGDClassifier(random_state=42)\n",
      "predict : \n",
      "[163000 163000 163000 106000 106000 163000 163000 106000 106000 106000\n",
      " 163000 106000 106000 106000 106000 106000 106000 106000 106000 106000\n",
      " 106000 106000 106000 106000 106000 106000 106000 106000 163000 106000\n",
      " 163000 106000 106000 106000 106000 106000 163000 163000 106000 163000\n",
      " 106000 106000 106000 163000 106000 106000 106000 106000 163000 163000\n",
      " 106000 106000 106000 106000 106000 106000 163000 106000 106000 106000\n",
      " 106000 106000 106000 106000 106000 106000 163000 163000 163000 106000\n",
      " 106000 106000 106000 106000 106000 163000 106000 163000 163000 106000\n",
      " 106000 106000 163000 106000 163000 106000 106000 106000 228500 106000\n",
      " 106000 163000 163000 163000 106000 106000 106000 106000 163000 106000\n",
      " 106000 106000 106000 163000 106000 106000 106000 163000 106000 163000\n",
      " 106000 106000 106000 163000 163000 106000 106000 106000 106000 163000\n",
      " 163000 106000 163000 163000 106000 163000 106000 163000 106000 106000\n",
      " 106000 106000 106000 106000 106000 106000 163000 163000 106000 106000\n",
      " 163000 106000 163000 106000 106000 106000 163000 106000 106000 106000\n",
      " 106000 106000 106000 106000 106000 106000 106000 106000 106000 163000\n",
      " 106000 106000 106000 106000 106000 106000 106000 106000 163000 106000\n",
      " 106000 106000 163000 106000 106000 106000 106000 106000 163000 163000\n",
      " 106000 106000 106000 163000 106000 106000 106000 163000 106000 106000\n",
      " 106000 106000 163000 106000 106000 106000 106000 106000 163000 163000\n",
      " 163000 106000 106000 163000 163000 106000 106000 106000 106000 106000\n",
      " 106000 106000 163000 106000 106000 163000 106000 163000 106000 106000\n",
      " 106000 163000 106000 106000 163000 106000 106000 106000 106000 106000\n",
      " 106000 106000 106000 106000 106000 106000 106000 106000 106000 163000\n",
      " 163000 163000 106000 163000 163000 106000 106000 106000 106000 106000\n",
      " 163000 106000 106000 106000 163000 163000 106000 106000 106000 163000\n",
      " 106000 106000 106000 106000 163000 106000 163000 106000 106000 228500\n",
      " 106000 106000 106000 106000 106000 106000 106000 106000 106000 106000\n",
      " 163000 163000 106000 106000 106000 106000 106000 106000 106000 163000\n",
      " 106000 106000]\n",
      "score   : \n",
      "0.0\n",
      "train-score   : \n",
      "0.0059931506849315065\n",
      "混同行列 : \n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "t_df = train_df[[\"SalePrice\",\"GrLivArea\",\"YearBuilt\"]]\n",
    "t_df = t_df.reindex([\"GrLivArea\",\"YearBuilt\",\"SalePrice\"], axis='columns') #並び替え\n",
    "\n",
    "home_x = t_df.loc[:,[\"GrLivArea\",\"YearBuilt\"]].values\n",
    "home_t = t_df[\"SalePrice\"].values\n",
    "\n",
    "hx_train, hx_test, hy_train, hy_test = scratch_train_test_split(home_x,home_t, train_size=0.8,seed=32)\n",
    "\n",
    "# \n",
    "# 1. 線形回帰\n",
    "# \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "lm_clf = SGDClassifier(random_state=42)\n",
    "\n",
    "print('1. 線形回帰')\n",
    "print(f'fitのデータ: \\n{lm_clf.fit(hx_train, hy_train)}')\n",
    "print(f'predict : \\n{lm_clf.predict(hx_test)}')   \n",
    "print(f'score   : \\n{lm_clf.score(hx_test, hy_test)}')   \n",
    "print(f'train-score   : \\n{lm_clf.score(hx_train, hy_train)}')   \n",
    "\n",
    "\n",
    "print(f'混同行列 : \\n{confusion_matrix(hy_test, lm_clf.predict(hx_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd888a-1918-4a52-8c6d-0163c00541cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
